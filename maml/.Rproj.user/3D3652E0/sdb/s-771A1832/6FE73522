{
    "contents" : "library(\"RCurl\")\nlibrary(\"rjson\")\nlibrary(\"data.table\")\nlibrary(\"df2json\")\nlibrary(\"jsonlite\")\nlibrary(\"httr\")\n\n# change scored prob\n\n#############################################################\n#' @title Consume File\n#' @description\n#' This function takes in an API key, file name and the request URL (OData Endpoint Address).\n#' It calls a helper function that sends requests to the server to the server in the appropriate format.\n#' It processes requests in batches and stores the responses in order of batches in an array. It returns the output columns along with the scored probablities, and stores the result in a text file.\n#' @param string api_key - API key must be entered as the first parameter\n#' @param string requestURL - must be entered as the third parameter\n#' @param string infileName - The name of the file that is being scored\n#' @param string globalParam - global parameters, default value is \"\"\n#' @param string outfileName - The name of the file to write results to, has a default value of \"results.txt\"\n#' @param int batchSize of each batch, which is optional, but 100 by default\n#' @param int retryDelay the time in seconds to delay before retrying in case of a server error, default value of 0.3 seconds\n#' @return results in a list of lists, with the scored probability at the end of each list\n#' @examples\n#'\n#############################################################\nconsumeFile <- function(api_key, requestURL, infileName, globalParam = setNames(list(), character(0)), outfileName = \"results.csv\", batchSize = 250, retryDelay = 0.3) {\n  if (missing(api_key)) {\n    stop(\"Need to specify API key\")\n  }\n  if (missing(infileName)) {\n    stop(\"Need to specify file to be scored\")\n  }\n  if (missing(requestURL)) {\n    stop(\"Need to specify request URL\")\n  }\n  #read file into dataframe, convert into dataframe\n  valuesDF = read.csv(infileName,check.names=FALSE)\n  df <- data.frame(stringsAsFactors=FALSE)\n  valuebatch = data.frame(stringsAsFactors=FALSE)\n  counter = 1\n  lastproc = 0\n\n  #process in batches and make API calls in batches\n  for(i in 1:(nrow(valuesDF))) {\n    if(counter == batchSize || i == (nrow(valuesDF))) {\n      resultDF = data.frame(stringsAsFactors=FALSE)\n      valuebatch = valuesDF[(lastproc+1):i,]\n      keyvalues = rjson::fromJSON((df2json::df2json(valuebatch)))\n      temp <- callAPI(api_key, requestURL, keyvalues, globalParam, retryDelay)\n      lastproc = i\n      resultStored <- jsonlite::fromJSON(temp)\n      resultList = resultStored$Results$output1\n      resultDF <- data.frame(resultList[,(ncol(resultList))])\n      if(length(df) != 0 && length(resultDF) != 0) {\n        names(df) <- names(resultDF)\n      }\n      df <- rbind(df,resultDF)\n\n      print(sprintf(\"%i %s %i %s\", i,\"out of\",nrow(valuesDF),\"processed\"))\n      valuebatch = data.frame(stringsAsFactors=FALSE)\n      counter = 0\n    }\n    counter = counter + 1\n  }\n  colnames(df) <- \"Scored probabilities\"\n\n  fileConn <-file(outfileName,\"w\")\n  write.csv(df, fileConn)\n  close(fileConn)\n  return (df)\n}\n\n\n\n#############################################################\n#' @title Consume Data Table\n#' @description\n#' This function takes in an API key, the request URL (OData Endpoint Address), the column names and multiple requests\n#' It scores the experiment with the requests stored in a list of lists, and sends it to the server in the appropriate format.\n#' It then obtains a response from Azure Machine Learning Studio and returns a response to the user. It returns the output column(s) along with the scored probablities!\n#' @param api key must be entered as the first parameter, and must be a string\n#' @param requestURL must be entered as the third parameter, and must be a string\n#' @param columnNames entered as a list\n#' @param ... each parameter must be a request in the format of a list that contains a row of values corresponsing to the column names provided\n#' @param globalParam global parameters entered as a string, default value is \"\"\n#' @param retryDelay the time in seconds to delay before retrying in case of a server error, default value of 0.3 seconds\n#' @return results in a list of lists, with the scored probability at the end of each list\n#' @examples\n#'\n#############################################################\nconsumeDataTable <- function(api_key, requestURL, columnNames, ..., globalParam=\"\", retryDelay = 0.3) {\n  if (missing(api_key)) {\n    stop(\"Need to specify API key\")\n  }\n\n  if (missing(requestURL)) {\n    stop(\"Need to specify request URL\")\n  }\n  if (missing(columnNames)) {\n    stop(\"Need to specify column names\")\n  }\n  if(missing(globalParam)) {\n    globalParam = \"\"\n  }\n  #store arguments as mega list of lists\n  valuesList <- lapply(X=list(...), function(x) x)\n  #make api call with components of payload\n  results <- callDTAPI(api_key, requestURL, columnNames, valuesList,  globalParam, retryDelay)\n  results <- jsonlite::fromJSON(results)\n\n  resultValues = results$Results$output1$value\n  # Previous lines were commented out, would not return correctly if there were multiple return values\n  #resultDF <- data.frame(resultList[,(ncol(resultList))])\n  #colnames(resultDF) = \"Scored probabilities\"\n  resultDF <- data.frame(resultValues$Values)\n  colnames(resultDF) <- resultValues$ColumnNames\n  return(resultDF)\n}\n\n\n\n#############################################################\n#' @title Consume Lists\n#' @description\n#' This function takes in an API key, the request URL (OData Endpoint Address), the column names and multiple requests\n#' It scores the experiment with the requests stored in a list of lists, and sends it to the server in the appropriate format.\n#' It then obtains a response from Azure Machine Learning Studio and returns a response to the user. It returns the output column(s) along with the scored probablities!\n#' @param string The api key must be entered as the first parameter\n#' @param string requestURL must be entered as the third parameter\n#' @param list columnNames - column Names\n#' @param ... each parameter must be a request in the format of a list that contains a row of values corresponding to the column names provided\n#' @param string globalParam - global parameters, default value is \"\"\n#' @param int retryDelay the time in seconds to delay before retrying in case of a server error, default value of 0.3 seconds\n#' @return results in a list of lists, with the scored probability at the end of each list\n#' @examples\n#'\n#############################################################\nconsumeLists <- function(api_key, requestURL, ..., globalParam = setNames(list(), character(0)), retryDelay = 0.3) {\n  if (missing(api_key)) {\n    stop(\"Need to specify API key\")\n  }\n\n  if (missing(requestURL)) {\n    stop(\"Need to specify request URL\")\n  }\n  if(missing(globalParam)) {\n    globalParam = setNames(list(), character(0))\n  }\n  df <- data.frame(stringsAsFactors=FALSE)\n  #store arguments as mega list of lists\n  keyvalues <- list(...)\n  #make api call with components of payload\n  temp <- callAPI(api_key, requestURL, keyvalues,  globalParam, retryDelay)\n  resultStored <- jsonlite::fromJSON(temp)\n  resultList = resultStored$Results$output1\n  resultDF <- data.frame(resultList[,(ncol(resultList))])\n\n  df <- rbind(df,resultDF)\n  colnames(df) <- \"Scored probabilities\"\n  return(df)\n}\n\n\n\n#############################################################\n#' @title Consume Data Frame\n#' @description\n#' This function takes in an API key, the request URL (OData Endpoint Address), the column names and multiple requests\n#' It scores the experiment with the requests stored in a list of lists, and sends it to the server in the appropriate format.\n#' It then obtains a response from Azure Machine Learning Studio and returns a response to the user. It returns the output column(s) along with the scored probablities!\n#' @param string The api key must be entered as the first parameter\n#' @param string requestURL must be entered as the second parameter\n#' @param string valuesDF - The name of the data frame that is being scored\n#' @param string globalParam - global parameters, default value is \"\"\n#' @param int batchSize of each batch, which is optional, but 100 by default\n#' @param int retryDelay the time in seconds to delay before retrying in case of a server error, default value of 0.3 seconds\n#' @return results in a list of lists, with the scored probability at the end of each list\n#' @examples\n#'\n#############################################################\nconsumeDataframe <- function(api_key, requestURL, valuesDF, globalParam=setNames(list(), character(0)), batchSize = 250, retryDelay = 0.3) {\n  if (missing(api_key)) {\n    stop(\"Need to specify API key\")\n  }\n\n  if (missing(requestURL)) {\n    stop(\"Need to specify request URL\")\n  }\n  if (missing(valuesDF)) {\n    stop(\"Need to specify dataframe to be scored\")\n  }\n  #format as matrix and parse column by column\n  columnNames = colnames(valuesDF)\n  matrixdf <- as.matrix(valuesDF)\n  rownames(matrixdf) <- NULL\n  colnames(matrixdf) <- NULL\n  matrixdf <- lapply(seq_len(nrow(matrixdf)), function(row) matrixdf[row,])\n  values = matrixdf\n  df <- data.frame(stringsAsFactors=FALSE)\n  valuebatch = list()\n  counter = 1\n\n  #process in batches and make API calls in batches\n  for(i in 1:(length(values))) {\n    valuebatch[length(valuebatch) + 1] = values[i]\n    if(counter == batchSize || i == (length(values))) {\n      temp <- callDTAPI(api_key, requestURL, columnNames, valuebatch, globalParam, retryDelay)\n      resultStored <- jsonlite::fromJSON(temp)\n      resultList = resultStored$Results$output1$value$Values\n      resultDF <- data.frame(resultList[,(ncol(resultList))])\n      #      print(resultDF)\n      #      print(is.data.frame(resultDF))\n      if(length(df) != 0 && length(resultDF) != 0) {\n        names(df) <- names(resultDF)\n      }\n      df <- rbind(df,resultDF)\n      colnames(df) <- \"Scored probabilities\"\n\n      #      print(\"passed\")\n      print(sprintf(\"%i %s %i %s\", i,\"out of\",length(values),\"processed\"))\n      valuebatch = list()\n      counter = 0\n    }\n    counter = counter + 1\n  }\n  colnames(df) <- \"Scored probabilities\"\n  return(df)\n  #   resultStored <- jsonlite::fromJSON(resultStored)\n  #   resultDF <- data.frame(matrix(resultStored$Results$output1$value$Values))\n  #   colnames(resultDF) <- resultStored$Results$output1$value$ColumnNames\n  #   return(resultDF)\n}\n\n\n\n#############################################################\n#' HELPER FUNCTION:\n#' This function is a helper that takes in an API key, values in the data table format and column names to pass to the API and the request URL (OData Endpoint Address).\n#' It then obtains a response from Azure Machine Learning Studio and returns a response to the consumeFile function.\n#############################################################\ncallDTAPI <- function(api_key, requestURL, columnNames, values,  globalParam, retryDelay) {\n  httpStatus = 0\n  tries = 0\n  # limit number of API calls to 3\n  for(i in 1:3) {\n    #make api calls and prepare payload if httpStatus indicates server error or if\n    if(tries == 0 || httpStatus >= 500) {\n      if(httpStatus >= 500) {\n        #delay by fixed or specified time if server error\n        print(paste(\"The request failed with status code:\", httpStatus, sep=\" \"))\n        print(\"headers:\")\n        print(headers)\n        print(sprintf(\"%s %f %s\", \"Retrying in \",retryDelay,\" seconds\"))\n        Sys.sleep(retryDelay)\n      }\n      tries = tries + 1\n      #construct request payload and load RCurl functions\n      options(RCurlOptions = list(cainfo = system.file(\"CurlSSL\", \"cacert.pem\", package = \"RCurl\")))\n      h = RCurl::basicTextGatherer()\n      hdr = RCurl::basicHeaderGatherer()\n      req = list(\n        Inputs = list(\n          \"input1\" = list(\n            \"ColumnNames\" = columnNames,\n            \"Values\" = values\n          )\n        )\n        ,GlobalParameters = globalParam\n      )\n      body = enc2utf8((rjson::toJSON(req)))\n\n      #make call to API after constructing request payload\n\n      authz_hdr = paste('Bearer', api_key, sep=' ')\n      h$reset()\n      RCurl::curlPerform(url = requestURL,\n                         httpheader=c('Content-Type' = \"application/json\", 'Authorization' = authz_hdr),\n                         postfields=body,\n                         writefunction = h$update,\n                         headerfunction = hdr$update,\n                         verbose = TRUE\n                         #                 Parameters below are needed if using test environment, but should not be included for security reasons\n                         ,ssl.verifypeer=FALSE,\n                         ssl.verifyhost = FALSE\n      )\n\n      headers = hdr$value()\n      httpStatus = headers[\"status\"]\n      result = h$value()\n      formatresult = result\n      #      formatresult <- jsonlite::toJSON(jsonlite::fromJSON(result), pretty = TRUE)\n\n    }\n    #return if successful\n    if(httpStatus == 200) {\n      return(formatresult)\n    }\n    #if user error, print and return error details\n    else if ((httpStatus>= 400) && (500 > httpStatus))\n    {\n      print(paste(\"The request failed with status code:\", httpStatus, sep=\" \"))\n      print(\"headers:\")\n      print(headers)\n      break\n    }\n  }\n  return(formatresult)\n}\n\n\n\n#############################################################\n#' HELPER FUNCTION:\n#' This function is a helper that takes in an API key, values in the key value format and column names to pass to the API and the request URL (OData Endpoint Address).\n#' It then obtains a response from Azure Machine Learning Studio and returns a response to the consumeFile function.\n#############################################################\ncallAPI <- function(api_key, requestURL, keyvalues,  globalParam, retryDelay) {\n  httpStatus = 0\n  tries = 0\n  # limit number of API calls to 3\n  for(i in 1:3) {\n    #make api calls and prepare payload if httpStatus indicates server error or if\n    if(tries == 0 || httpStatus >= 500) {\n      if(httpStatus >= 500) {\n        #delay by fixed or specified time if server error\n        print(paste(\"The request failed with status code:\", httpStatus, sep=\" \"))\n        print(\"headers:\")\n        print(headers)\n        print(sprintf(\"%s %f %s\", \"Retrying in \",retryDelay,\" seconds\"))\n        Sys.sleep(retryDelay)\n      }\n      tries = tries + 1\n      #construct request payload and load RCurl functions\n      options(RCurlOptions = list(cainfo = system.file(\"CurlSSL\", \"cacert.pem\", package = \"RCurl\")))\n      h = RCurl::basicTextGatherer()\n      hdr = RCurl::basicHeaderGatherer()\n      req = list(\n        Inputs = list(\n          input1 = keyvalues\n        )\n        ,GlobalParameters = globalParam\n      )\n      body = enc2utf8((rjson::toJSON(req)))\n      print(body)\n\n      #make call to API after constructing request payload\n\n      authz_hdr = paste('Bearer', api_key, sep=' ')\n      h$reset()\n      RCurl::curlPerform(url = requestURL,\n                         httpheader=c('Content-Type' = \"application/json\", 'Authorization' = authz_hdr),\n                         postfields=body,\n                         writefunction = h$update,\n                         headerfunction = hdr$update,\n                         verbose = TRUE\n                         #                 Parameters below are needed if using test environment, but should not be included for security reasons\n                         ,ssl.verifypeer=FALSE,\n                         ssl.verifyhost = FALSE\n      )\n\n      headers = hdr$value()\n      httpStatus = headers[\"status\"]\n      result = h$value()\n      formatresult = result\n\n    }\n    #return if successful\n    if(httpStatus == 200) {\n      return(formatresult)\n    }\n    #if user error, print and return error details\n    else if ((httpStatus>= 400) && (500 > httpStatus))\n    {\n      print(paste(\"The request failed with status code:\", httpStatus, sep=\" \"))\n      print(\"headers:\")\n      print(headers)\n      break\n    }\n  }\n  return(formatresult)\n}\n\n\n\n#############################################################\n#############################################################\ndiscoverSchema <- function(wkID, token, schemes = \"https\", host = \"requestresponse001.cloudapp.net:443\", api_version = \"2.0\") {\n  # swagger document:\n  # schemes://hostbasepath/\"swagger.json?api-version=2.0\"\n  swaggerURL = paste(schemes,\"://\", host, \"/workspaces/\", wkID, \"/services/\", token,\"/swagger.json?api-version=\",api_version, sep = \"\")\n\n\n  httr::set_config(config(ssl_VERIFYHOST=FALSE,ssl_verifyPEER=FALSE), override=TRUE)\n  resp <- httr::GET(swaggerURL)\n\n  swagger <- httr::content(resp)\n\n  # condensed three steps into one line: Access JSON and then use rjson and json lite in order to structure it as a layered json object\n  inputschema = jsonlite::toJSON(jsonlite::fromJSON((rjson::toJSON(swagger$definitions$ExecutionInputs))), pretty = TRUE)\n  inputexample <- jsonlite::toJSON(jsonlite::fromJSON((rjson::toJSON(swagger$definitions$ExecutionRequest$example))), pretty = TRUE)\n\n  #find the path where operationId is execute\n  foundExec = FALSE\n  pathno = 0\n  foundpathindex= -1\n  for(execpath in swagger$paths) {\n    pathno = pathno + 1\n    for(operationpath in execpath) {\n      for(operation in operationpath) {\n        for(charac in operation) {\n          if(charac[1] == \"execute\")\n          {\n            foundExec = TRUE\n            foundpathindex = pathno\n            break\n          }\n        }\n      }\n    }\n  }\n\n  executepath = names(swagger$paths)[[foundpathindex]]\n  httpMethod = toupper(names(swagger$paths[[2]]))\n  # requestURL:\n  #   \"https://requestresponse001.cloudapp.net:443/workspaces/7e8f135f31274b7eac419bd056875c03/services/a5b003e52c924d16a2e38ade45dd0154/execute?api-version=2.0&format=swagger\"\n  #   schemes://hostbasepath(path where operationId=\"execute\")\n  requestURL = paste(schemes,\"://\", host, \"/workspaces/\", wkID, \"/services/\", token, executepath, sep = \"\")\n\n  httpRequest = paste(httpMethod,requestURL)\n  #tell user what they can do\n  if(foundExec) {\n    consumefile = paste(\"consumeFile(api_key, requestURL, dataframe)\")\n    consumedf = paste(\"consumeDataframe(api_key, requestURL, valuesDF)\")\n    consumelists = paste(\"consumeLists(api_key, requestURL, ...)\")\n    consumedt = paste(\"consumeFile(api_key, requestURL, columnNames, ...)\")\n\n    cat(\"Sample functions to execute the web service and get a response synchronously:\",\"\\n\", consumefile,\"\\n\", consumedf,\"\\n\", consumelists,\"\\n\", consumedt,\"\\n\",\"\\n\")\n\n  }\n\n  return (list(\"Request URL:\" = requestURL, \"Sample input:\" = inputexample, \"Input schema:\" = inputschema))\n}\n",
    "created" : 1437517533298.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "4096582585",
    "id" : "6FE73522",
    "lastKnownWriteTime" : 1437589498,
    "path" : "~/GitHub/Azure-MachineLearning-ClientLibrary-R/maml/R/consume.R",
    "project_path" : "R/consume.R",
    "properties" : {
    },
    "source_on_save" : false,
    "type" : "r_source"
}