temp <- callAPI(api_key, requestURL, keyvalues,  globalParam, retryDelay)
resultStored <- jsonlite::fromJSON(temp)
resultList = resultStored$Results$output1
resultDF <- data.frame(resultList[,(ncol(resultList))])
df <- rbind(df,resultDF)
colnames(df) <- "Scored probabilities"
return(df)
}
#############################################################
#' @title Consume Data Frame
#' @description
#' This function takes in an API key, the request URL (OData Endpoint Address), the column names and multiple requests
#' It scores the experiment with the requests stored in a list of lists, and sends it to the server in the appropriate format.
#' It then obtains a response from Azure Machine Learning Studio and returns a response to the user. It returns the output column(s) along with the scored probablities!
#' @param string The api key must be entered as the first parameter
#' @param string requestURL must be entered as the second parameter
#' @param string valuesDF - The name of the data frame that is being scored
#' @param string globalParam - global parameters, default value is ""
#' @param int batchSize of each batch, which is optional, but 100 by default
#' @param int retryDelay the time in seconds to delay before retrying in case of a server error, default value of 0.3 seconds
#' @return results in a list of lists, with the scored probability at the end of each list
#' # add examples
#'
#############################################################
consumeDataframe <- function(api_key, requestURL, valuesDF, globalParam=setNames(list(), character(0)), batchSize = 250, retryDelay = 0.3) {
if (missing(api_key)) {
stop("Need to specify API key")
}
if (missing(requestURL)) {
stop("Need to specify request URL")
}
if (missing(valuesDF)) {
stop("Need to specify dataframe to be scored")
}
#format as matrix and parse column by column
columnNames = colnames(valuesDF)
matrixdf <- as.matrix(valuesDF)
rownames(matrixdf) <- NULL
colnames(matrixdf) <- NULL
matrixdf <- lapply(seq_len(nrow(matrixdf)), function(row) matrixdf[row,])
values = matrixdf
df <- data.frame(stringsAsFactors=FALSE)
valuebatch = list()
counter = 1
#process in batches and make API calls in batches
for(i in 1:(length(values))) {
valuebatch[length(valuebatch) + 1] = values[i]
if(counter == batchSize || i == (length(values))) {
temp <- callDTAPI(api_key, requestURL, columnNames, valuebatch, globalParam, retryDelay)
resultStored <- jsonlite::fromJSON(temp)
resultList = resultStored$Results$output1$value$Values
resultDF <- data.frame(resultList[,(ncol(resultList))])
#      print(resultDF)
#      print(is.data.frame(resultDF))
if(length(df) != 0 && length(resultDF) != 0) {
names(df) <- names(resultDF)
}
df <- rbind(df,resultDF)
colnames(df) <- "Scored probabilities"
#      print("passed")
print(sprintf("%i %s %i %s", i,"out of",length(values),"processed"))
valuebatch = list()
counter = 0
}
counter = counter + 1
}
colnames(df) <- "Scored probabilities"
return(df)
#   resultStored <- jsonlite::fromJSON(resultStored)
#   resultDF <- data.frame(matrix(resultStored$Results$output1$value$Values))
#   colnames(resultDF) <- resultStored$Results$output1$value$ColumnNames
#   return(resultDF)
}
#############################################################
#' HELPER FUNCTION:
#' This function is a helper that takes in an API key, values in the data table format and column names to pass to the API and the request URL (OData Endpoint Address).
#' It then obtains a response from Azure Machine Learning Studio and returns a response to the consumeFile function.
#############################################################
callDTAPI <- function(api_key, requestURL, columnNames, values,  globalParam, retryDelay) {
httpStatus = 0
tries = 0
# limit number of API calls to 3
for(i in 1:3) {
#make api calls and prepare payload if httpStatus indicates server error or if
if(tries == 0 || httpStatus >= 500) {
if(httpStatus >= 500) {
#delay by fixed or specified time if server error
print(paste("The request failed with status code:", httpStatus, sep=" "))
print("headers:")
print(headers)
print(sprintf("%s %f %s", "Retrying in ",retryDelay," seconds"))
Sys.sleep(retryDelay)
}
tries = tries + 1
#construct request payload and load RCurl functions
options(RCurlOptions = list(cainfo = system.file("CurlSSL", "cacert.pem", package = "RCurl")))
h = RCurl::basicTextGatherer()
hdr = RCurl::basicHeaderGatherer()
req = list(
Inputs = list(
"input1" = list(
"ColumnNames" = columnNames,
"Values" = values
)
)
,GlobalParameters = globalParam
)
body = enc2utf8((rjson::toJSON(req)))
#make call to API after constructing request payload
authz_hdr = paste('Bearer', api_key, sep=' ')
h$reset()
RCurl::curlPerform(url = requestURL,
httpheader=c('Content-Type' = "application/json", 'Authorization' = authz_hdr),
postfields=body,
writefunction = h$update,
headerfunction = hdr$update,
verbose = TRUE
#                 Parameters below are needed if using test environment, but should not be included for security reasons
,ssl.verifypeer=FALSE,
ssl.verifyhost = FALSE
)
headers = hdr$value()
httpStatus = headers["status"]
result = h$value()
formatresult = result
#      formatresult <- jsonlite::toJSON(jsonlite::fromJSON(result), pretty = TRUE)
}
#return if successful
if(httpStatus == 200) {
return(formatresult)
}
#if user error, print and return error details
else if ((httpStatus>= 400) && (500 > httpStatus))
{
print(paste("The request failed with status code:", httpStatus, sep=" "))
print("headers:")
print(headers)
print(h$value())
break
}
}
return(formatresult)
}
#############################################################
#' HELPER FUNCTION:
#' This function is a helper that takes in an API key, values in the key value format and column names to pass to the API and the request URL (OData Endpoint Address).
#' It then obtains a response from Azure Machine Learning Studio and returns a response to the consumeFile function.
#############################################################
callAPI <- function(api_key, requestURL, keyvalues,  globalParam, retryDelay) {
httpStatus = 0
tries = 0
# limit number of API calls to 3
for(i in 1:3) {
#make api calls and prepare payload if httpStatus indicates server error or if
if(tries == 0 || httpStatus >= 500) {
if(httpStatus >= 500) {
#delay by fixed or specified time if server error
print(paste("The request failed with status code:", httpStatus, sep=" "))
print("headers:")
print(headers)
print(sprintf("%s %f %s", "Retrying in ",retryDelay," seconds"))
Sys.sleep(retryDelay)
}
tries = tries + 1
#construct request payload and load RCurl functions
options(RCurlOptions = list(cainfo = system.file("CurlSSL", "cacert.pem", package = "RCurl")))
h = RCurl::basicTextGatherer()
hdr = RCurl::basicHeaderGatherer()
req = list(
Inputs = list(
input1 = keyvalues
)
,GlobalParameters = globalParam
)
body = enc2utf8((rjson::toJSON(req)))
print(body)
#make call to API after constructing request payload
authz_hdr = paste('Bearer', api_key, sep=' ')
h$reset()
RCurl::curlPerform(url = requestURL,
httpheader=c('Content-Type' = "application/json", 'Authorization' = authz_hdr),
postfields=body,
writefunction = h$update,
headerfunction = hdr$update,
verbose = TRUE
#                 Parameters below are needed if using test environment, but should not be included for security reasons
,ssl.verifypeer=FALSE,
ssl.verifyhost = FALSE
)
headers = hdr$value()
httpStatus = headers["status"]
result = h$value()
formatresult = result
}
#return if successful
if(httpStatus == 200) {
return(formatresult)
}
#if user error, print and return error details
else if ((httpStatus>= 400) && (500 > httpStatus))
{
print(paste("The request failed with status code:", httpStatus, sep=" "))
print("headers:")
print(headers)
break
}
}
return(formatresult)
}
#############################################################
#############################################################
discoverSchema <- function(wkID, token, schemes = "https", host = "requestresponse001.cloudapp.net:443", api_version = "2.0") {
# swagger document:
# schemes://hostbasepath/"swagger.json?api-version=2.0"
swaggerURL = paste(schemes,"://", host, "/workspaces/", wkID, "/services/", token,"/swagger.json?api-version=",api_version, sep = "")
httr::set_config(config(ssl_VERIFYHOST=FALSE,ssl_verifyPEER=FALSE), override=TRUE)
resp <- httr::GET(swaggerURL)
swagger <- httr::content(resp)
# condensed three steps into one line: Access JSON and then use rjson and json lite in order to structure it as a layered json object
inputschema = jsonlite::toJSON(jsonlite::fromJSON((rjson::toJSON(swagger$definitions$ExecutionInputs))), pretty = TRUE)
inputexample <- jsonlite::toJSON(jsonlite::fromJSON((rjson::toJSON(swagger$definitions$ExecutionRequest$example))), pretty = TRUE)
#find the path where operationId is execute
foundExec = FALSE
pathno = 0
foundpathindex= -1
for(execpath in swagger$paths) {
pathno = pathno + 1
for(operationpath in execpath) {
for(operation in operationpath) {
for(charac in operation) {
if(charac[1] == "execute")
{
foundExec = TRUE
foundpathindex = pathno
break
}
}
}
}
}
executepath = names(swagger$paths)[[foundpathindex]]
httpMethod = toupper(names(swagger$paths[[2]]))
# requestURL:
#   "https://requestresponse001.cloudapp.net:443/workspaces/7e8f135f31274b7eac419bd056875c03/services/a5b003e52c924d16a2e38ade45dd0154/execute?api-version=2.0&format=swagger"
#   schemes://hostbasepath(path where operationId="execute")
requestURL = paste(schemes,"://", host, "/workspaces/", wkID, "/services/", token, executepath, sep = "")
httpRequest = paste(httpMethod,requestURL)
#tell user what they can do
if(foundExec) {
consumefile = paste("consumeFile(api_key, requestURL, dataframe)")
consumedf = paste("consumeDataframe(api_key, requestURL, valuesDF)")
consumelists = paste("consumeLists(api_key, requestURL, ...)")
consumedt = paste("consumeFile(api_key, requestURL, columnNames, ...)")
cat("Sample functions to execute the web service and get a response synchronously:","\n", consumefile,"\n", consumedf,"\n", consumelists,"\n", consumedt,"\n","\n")
}
return (list("Request URL:" = requestURL, "Sample input:" = inputexample, "Input schema:" = inputschema))
}
endpoints <- bikeCount[[2]]
response <- consumeDataTable(endpoints[[1]]["PrimaryKey"], paste(endpoints[[1]]["ApiLocation"], "/execute?api-version=2.0&details=true",sep=""),
list("dteday"="date-time", "mnth"="int", "hr"="int", "holiday"="int", "workingday"="int", "weathersit"="int",
"temp"="int", "hum"="int", "windspeed"="int", "casual"="int", "registered"="int", "cnt"="int",
"isWorking"="int", "monthCount"="int", "dayWeek"="int", "workTime"="int", "xformHr"="int"),
list("1/1/12 12:00:00", 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1))
getFunctionString(predictBikeCount())
predictBikeCount("1/1/12 12:00:00", 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1)
response <- consumeDataTable(endpoints[[1]]["PrimaryKey"], paste(endpoints[[1]]["ApiLocation"], "/execute?api-version=2.0&details=true",sep=""),
list("dteday", "mnth", "hr", "holiday", "workingday", "weathersit",
"temp", "hum", "windspeed", "casual", "registered", "cnt",
"isWorking", "monthCount", "dayWeek", "workTime", "xformHr"),
list("1/1/12 12:00:00", 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1))
cat("{\"error\":{\"code\":\"LibraryExecutionError\",\"message\":\"Module execution encountered an internal library error.\",\"details\":[{\"code\":\"FailedToEvaluateRScript\",\"target\":\"Execute R Script Piped (RPackage)\",\"message\":\"The following error occurred during evaluation of R script: R_tryEval: return error: Error in action(dteday = \\\"1/1/12 12:00:00\\\", mnth = 1L, hr = 1L, holiday = 1L,  : \\n  unused arguments (dteday = \\\"1/1/12 12:00:00\\\", mnth = 1, holiday = 1, workingday = 1, weathersit = 1, windspeed = 1, monthCount = 1, workTime = 1)\\n\"}]}}")
head(BikeShare)
bikeCount <- publishWebService("predictBikeCount", "bikeCount", list("dteday"="date-time", "month"="int", "hr"="int", "hldy"="int", "wkdy"="int", "weather"="int",
"temp"="int", "hum"="int", "wndspd"="int", "casual"="int", "registered"="int", "cnt"="int",
"isWorking"="int", "mnthCnt"="int", "dayWeek"="int", "wrkTime"="int", "xformHr"="int"),
list("count"="int"), wsID, wsAuth)
response
endpoints <- bikeCount[[2]]
response <- consumeDataTable(endpoints[[1]]["PrimaryKey"], paste(endpoints[[1]]["ApiLocation"], "/execute?api-version=2.0&details=true",sep=""),
list("dteday", "month", "hr", "holiday", "workingday", "weathersit",
"temp", "hum", "windspeed", "casual", "registered", "cnt",
"isWorking", "monthCount", "dayWeek", "workTime", "xformHr"),
list("1/1/12 12:00:00", 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1))
predictBikeCount <- function(dateTime, month, hr, hldy, wkdy, weather, temp, hum,
wndspd, casual, registered, cnt, isWorking, mthCnt, dayWeek, wrkTime, xformHr) {
return(predict(rf.bike, newdata=data.frame("dteday"=dateTime, "mnth"=month, "hr"=hr, "holiday"=hldy, "workingday"=wkdy, "weathersit"=weather,
"temp"=temp, "hum"=hum, "windspeed"=wndspd, "casual"=casual, "registered"=registered, "cnt"=cnt,
"isWorking"=isWorking, "monthCount"=mthCnt, "dayWeek"=dayWeek, "workTime"=wrkTime, "xformHr"=xformHr)))
}
bikeCount <- publishWebService("predictBikeCount", "bikeCount", list("dateTime"="date-time", "month"="int", "hr"="int", "hldy"="int", "wkdy"="int", "weather"="int",
"temp"="int", "hum"="int", "wndspd"="int", "casual"="int", "registered"="int", "cnt"="int",
"isWorking"="int", "mnthCnt"="int", "dayWeek"="int", "wrkTime"="int", "xformHr"="int"),
list("count"="int"), wsID, wsAuth)
bikeCount[[1]]
endpoints <- bikeCount[[2]]
response <- consumeDataTable(endpoints[[1]]["PrimaryKey"], paste(endpoints[[1]]["ApiLocation"], "/execute?api-version=2.0&details=true",sep=""),
list("dteday", "month", "hr", "holiday", "workingday", "weathersit",
"temp", "hum", "windspeed", "casual", "registered", "cnt",
"isWorking", "monthCount", "dayWeek", "workTime", "xformHr"),
list("1/1/12 12:00:00", 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1))
response <- consumeDataTable(endpoints[[1]]["PrimaryKey"], paste(endpoints[[1]]["ApiLocation"], "/execute?api-version=2.0&details=true",sep=""),
list("dateTime", "month", "hr", "hldy", "wkdy", "weather",
"temp", "hum", "wndspd", "casual", "registered", "cnt",
"isWorking", "mthCnt", "dayWeek", "wrkTime", "xformHr"),
list("1/1/12 12:00:00", 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1))
bikeCount <- publishWebService("predictBikeCount", "bikeCount", list("dateTime"="date-time", "month"="int", "hr"="int", "hldy"="int", "wkdy"="int", "weather"="int",
"temp"="int", "hum"="int", "wndspd"="int", "casual"="int", "registered"="int", "cnt"="int",
"isWorking"="int", "mthCnt"="int", "dayWeek"="int", "wrkTime"="int", "xformHr"="int"),
list("count"="int"), wsID, wsAuth)
endpoints <- bikeCount[[2]]
response <- consumeDataTable(endpoints[[1]]["PrimaryKey"], paste(endpoints[[1]]["ApiLocation"], "/execute?api-version=2.0&details=true",sep=""),
list("dateTime", "month", "hr", "hldy", "wkdy", "weather",
"temp", "hum", "wndspd", "casual", "registered", "cnt",
"isWorking", "mthCnt", "dayWeek", "wrkTime", "xformHr"),
list("1/1/12 12:00:00", 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1))
endpoints <- bikeCount[[2]]
response <- consumeDataTable(endpoints[[1]]["PrimaryKey"], paste(endpoints[[1]]["ApiLocation"], "/execute?api-version=2.0&details=true",sep=""),
list("dateTime", "month", "hr", "hldy", "wkdy", "weather",
"temp", "hum", "wndspd", "casual", "registered", "cnt",
"isWorking", "mthCnt", "dayWeek", "wrkTime", "xformHr"),
list("1/1/12 12:00:00", 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1))
endpoints <- bikeCount[[2]]
response <- consumeDataTable(endpoints[[1]]["PrimaryKey"], paste(endpoints[[1]]["ApiLocation"], "/execute?api-version=2.0&details=true",sep=""),
list("dateTime", "month", "hr", "hldy", "wkdy", "weather",
"temp", "hum", "wndspd", "casual", "registered", "cnt",
"isWorking", "mthCnt", "dayWeek", "wrkTime", "xformHr"),
list("1/1/12 12:00:00", 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1))
?tryCatch
packDependencies <- function(functionName) {
# lists for storing objects and packages
dependencies = list()
packages = list()
# generate a GUID to act as a file name to store packages, R data
guid = gsub("-", "", uuid::UUIDgenerate(use.time=TRUE))
# NOTE: will not work if the user function specifies the names directly, e.g. won't find rjson::toJSON
# from findGlobals man page: "R semantics only allow variables that might be local to be identified"
# CONSIDER: how robust is this filtering? need to verify
for (obj in codetools::findGlobals(get(functionName))) {
name = get(obj)
print(obj)
# filter out primitives and duplicates
if (is.primitive(name) || (obj %in% names(dependencies))) {
next
}
# get in-memory objects
else if (!is.function(name)) {
dependencies[[obj]] <- name
objClass <- class(name)
#nameEnv <- environment(get(class(name)))
for (class in objClass) {
tryCatch({
nameEnv <- environment(get(class))
if (!(identical(nameEnv, NULL)) && !(identical(nameEnv, .BaseNamespaceEnv))) {
packages <- recurPkg(paste(getNamespaceName(nameEnv)), packages)
}
}, error = function(e) {
sprintf("%s not found", obj)
})
print("here")
}
}
# grab user defined functions
else if (identical(environment(name), globalenv())) {
dependencies[[obj]] <- name
# recursively get dependencies
results <- recurDep(obj, dependencies, packages)
dependencies <- results$dependencies
packages <- results$packages
}
# get the names of packages of package functions
# filter out base functions
else if (paste(getNamespaceName(environment(name))) != "base") {
# recursively get packages
packages <- recurPkg(paste(getNamespaceName(environment(name))), packages)
}
# need an else branch?
}
# save current path to restore to later
start = getwd()
# go to package library, doing this to prevent zipping entire package
toPack <- packages
toZip = vector()
for (i in 1:length(.libPaths())) {
setwd(.libPaths()[i])
# try to find and zip up the packages
for (pkg in toPack) {
if (file.exists(pkg)) {
zip(paste(start, paste(pkg, "zip", sep="."), sep="/"), pkg)
toZip <- c(toZip, paste(pkg, "zip", sep="."))
toPack <- toPack[toPack != pkg]
}
}
# if done packing, break
if (length(toPack) == 0) {
break
}
if (i == length(.libPaths())) {
# error: can't find packages
stop("Error: unable to locate packages. Please make sure the packages used are in at least one of the library paths.")
}
}
# go back to where the user started
setwd(start)
# objects, functions, etc.
if (length(dependencies) > 0) {
# maybe can save directly as a .zip and skip the zip() call?
save(dependencies, file=guid)
toZip <- c(toZip, guid)
}
# zip up everything
if (length(toZip) > 0) {
zip(zipfile=guid, files=toZip)
zipEnc <- base64enc::base64encode(paste(guid, ".zip", sep=""))
# delete the packages
for (pkg in packages) {
# did I miss anything? maybe extra files floating around
file.remove(paste(pkg, "zip", sep="."))
}
if (length(dependencies) > 0) {
# delete the dependency rdta file
file.remove(guid)
file.remove(paste(guid,"zip",sep="."))
}
# return the encoded zip as a string
return(list(guid, zipEnc))
}
# if nothing was zipped, return false
else {
return(list(guid, ""))
}
}
bikeCount <- publishWebService("predictBikeCount", "bikeCount", list("dateTime"="date-time", "month"="int", "hr"="int", "hldy"="int", "wkdy"="int", "weather"="int",
"temp"="int", "hum"="int", "wndspd"="int", "casual"="int", "registered"="int", "cnt"="int",
"isWorking"="int", "mthCnt"="int", "dayWeek"="int", "wrkTime"="int", "xformHr"="int"),
list("count"="int"), wsID, wsAuth)
endpoints <- bikeCount[[2]]
response <- consumeDataTable(endpoints[[1]]["PrimaryKey"], paste(endpoints[[1]]["ApiLocation"], "/execute?api-version=2.0&details=true",sep=""),
list("dateTime", "month", "hr", "hldy", "wkdy", "weather",
"temp", "hum", "wndspd", "casual", "registered", "cnt",
"isWorking", "mthCnt", "dayWeek", "wrkTime", "xformHr"),
list("1/1/12 12:00:00", 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1))
response
setwd("C://Users/t-alewa/Documents/Azure-MachineLearning-ClientLibrary-R/test")
library(randomForest)
dataset <- read.csv(file="rfData.csv")
model <- randomForest(Count ~ ., dataset)
head(dataset)
dataset <- read.csv(file="breastCancer.csv")
head(dataset)
fit <- kmeans(dataset, 5)
fit
?kmeans
head(dataset)
fit$cluster[-1]
fit$cluster[[-1]]
getCluster <- function (age, mp, tSize, invNodes, nodeCaps, DegMalig, Breast, BreastQuad, Irradiat) {
fit <- kmeans(rbind(dataset, data.frame("age"=age,"menopause"=mp, "tumor.size"=tSize, "inv.nodes"=invNodes,
"node.caps"=nodeCaps, "deg.malig"=DegMalig, "breast"=Breast, "breast.quad"=BreastQuad,
"irradiat"=Irradiat)),5)
return(tail(fit$cluster, n=1))
}
head(dataset)
getCluster(7, 2, 3, 4, 2, 3, 2, 1, 1)
onlineCluster <- publishWebService("getCluster", "kMeansCancer", list("age"="int","menopause"="int", "tumor.size"="int", "inv.nodes"="int",
"node.caps"="int", "deg.malig"="int", "breast"="int", "breast.quad"="int",
"irradiat"="int"), list("cluster"="int"), wsID, wsAuth)
endpoints <- onlineCluster[[2]]
responseDF <- consumeDataframe(endpoints[[1]]$PrimaryKey, paste(endpoints[[1]]$ApiLocation,"/execute?api-version=2.0&details=true",sep=""),
list("age", "mp", "tSize", "invNodes", "nodeCaps", "DegMalig", "Breast", "BreastQuad", "Irradiat"),
list(7, 2, 3, 4, 2, 3, 2, 1, 1))
responseDF <- consumeDataframe(endpoints[[1]]$PrimaryKey, paste(endpoints[[1]]$ApiLocation,"/execute?api-version=2.0&details=true",sep=""),
list("age", "mp", "tSize", "invNodes", "nodeCaps", "DegMalig", "Breast", "BreastQuad", "Irradiat"),
list(7, 2, 3, 4, 2, 3, 2, 1, 1))
endpoints <- onlineCluster[[2]]
responseDF <- consumeDataframe(endpoints[[1]]$PrimaryKey, paste(endpoints[[1]]$ApiLocation,"/execute?api-version=2.0&details=true",sep=""),
list("age", "mp", "tSize", "invNodes", "nodeCaps", "DegMalig", "Breast", "BreastQuad", "Irradiat"),
list(7, 2, 3, 4, 2, 3, 2, 1, 1))
getCluster <- function (age, mp, tSize, invNodes, nodeCaps, DegMalig, Breast, BreastQuad, Irradiat) {
fit <- kmeans(rbind(dataset, data.frame("age"=age,"menopause"=mp, "tumor.size"=tSize, "inv.nodes"=invNodes,
"node.caps"=nodeCaps, "deg.malig"=DegMalig, "breast"=Breast, "breast.quad"=BreastQuad,
"irradiat"=Irradiat)),5)
return(fit$cluster[[length(fit$cluster)]])
}
onlineCluster <- publishWebService("getCluster", "kMeansCancer", list("age"="int","menopause"="int", "tumor.size"="int", "inv.nodes"="int",
"node.caps"="int", "deg.malig"="int", "breast"="int", "breast.quad"="int",
"irradiat"="int"), list("cluster"="int"), wsID, wsAuth)
endpoints <- onlineCluster[[2]]
r
responseDF <- consumeDataframe(endpoints[[1]]$PrimaryKey, paste(endpoints[[1]]$ApiLocation,"/execute?api-version=2.0&details=true",sep=""),
list("age", "mp", "tSize", "invNodes", "nodeCaps", "DegMalig", "Breast", "BreastQuad", "Irradiat"),
list(7, 2, 3, 4, 2, 3, 2, 1, 1))
responseDF <- consumeDataframe(endpoints[[1]]$PrimaryKey, paste(endpoints[[1]]$ApiLocation,"/execute?api-version=2.0&details=true",sep=""),
list("age", "mp", "tSize", "invNodes", "nodeCaps", "DegMalig", "Breast", "BreastQuad", "Irradiat"),
list(7, 2, 3, 4, 2, 3, 2, 1, 1))
getCluster(7, 2, 3, 4, 2, 3, 2, 1, 1)
responseDF <- consumeDataTable(endpoints[[1]]$PrimaryKey, paste(endpoints[[1]]$ApiLocation,"/execute?api-version=2.0&details=true",sep=""),
list("age", "mp", "tSize", "invNodes", "nodeCaps", "DegMalig", "Breast", "BreastQuad", "Irradiat"),
list(7, 2, 3, 4, 2, 3, 2, 1, 1))
responseDF <- consumeDataTable(endpoints[[1]]$PrimaryKey, paste(endpoints[[1]]$ApiLocation,"/execute?api-version=2.0&details=true",sep=""),
list("age", "menopause", "tumor.size", "inv.nodes", "node.caps", "deg.malig", "breast", "breast.quad", "irradiat"),
list(7, 2, 3, 4, 2, 3, 2, 1, 1))
onlineCluster <- publishWebService("getCluster", "kMeansCancer", list("age"="int","mp"="int", "tSize"="int", "invNodes"="int",
"nodeCaps"="int", "DegMalig"="int", "Breast"="int", "BreastQuad"="int",
"Irradiat"="int"), list("cluster"="int"), wsID, wsAuth)
endpoints <- onlineCluster[[2]]
responseDF <- consumeDataTable(endpoints[[1]]$PrimaryKey, paste(endpoints[[1]]$ApiLocation,"/execute?api-version=2.0&details=true",sep=""),
list("age", "mp", "tSize", "invNodes", "nodeCaps", "DegMalig", "Breast", "BreastQuad", "Irradiat"),
list(7, 2, 3, 4, 2, 3, 2, 1, 1))
responseDF <- consumeDataTable(endpoints[[1]]$PrimaryKey, paste(endpoints[[1]]$ApiLocation,"/execute?api-version=2.0&details=true",sep=""),
list("age", "mp", "tSize", "invNodes", "nodeCaps", "DegMalig", "Breast", "BreastQuad", "Irradiat"),
list(7, 2, 3, 4, 2, 3, 2, 1, 1))
responseDF
